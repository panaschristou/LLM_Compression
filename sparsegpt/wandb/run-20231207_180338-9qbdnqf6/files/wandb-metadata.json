{
    "os": "Linux-4.18.0-372.26.1.el8_6.x86_64-x86_64-with-glibc2.35",
    "python": "3.11.5",
    "heartbeatAt": "2023-12-07T23:03:39.389271",
    "startedAt": "2023-12-07T23:03:38.913737",
    "docker": null,
    "cuda": null,
    "args": [
        "LLAMA_HF_WEIGHTS_LOCATION",
        "c4",
        "--sparsity",
        "0.5",
        "--save",
        "output/llama_0.5",
        "--log_wandb"
    ],
    "state": "running",
    "program": "/scratch/xc1490/projects/hpml/project/sparsegpt/llama.py",
    "codePath": "llama.py",
    "git": {
        "remote": "https://github.com/IST-DASLab/sparsegpt.git",
        "commit": "c3bbf613a1822229767f4d8870b933049b8bef15"
    },
    "email": "240682348@qq.com",
    "root": "/scratch/xc1490/projects/hpml/project/sparsegpt",
    "host": "gv010.hpc.nyu.edu",
    "username": "xc1490",
    "executable": "/ext3/miniconda3/bin/python",
    "cpu_count": 48,
    "cpu_count_logical": 48,
    "cpu_freq": {
        "current": 3.857687500000003,
        "min": 3900.0,
        "max": 3900.0
    },
    "cpu_freq_per_core": [
        {
            "current": 3.9,
            "min": 3900.0,
            "max": 3900.0
        },
        {
            "current": 3.499,
            "min": 3900.0,
            "max": 3900.0
        },
        {
            "current": 3.9,
            "min": 3900.0,
            "max": 3900.0
        },
        {
            "current": 3.9,
            "min": 3900.0,
            "max": 3900.0
        },
        {
            "current": 3.9,
            "min": 3900.0,
            "max": 3900.0
        },
        {
            "current": 3.9,
            "min": 3900.0,
            "max": 3900.0
        },
        {
            "current": 3.9,
            "min": 3900.0,
            "max": 3900.0
        },
        {
            "current": 3.9,
            "min": 3900.0,
            "max": 3900.0
        },
        {
            "current": 3.9,
            "min": 3900.0,
            "max": 3900.0
        },
        {
            "current": 3.9,
            "min": 3900.0,
            "max": 3900.0
        },
        {
            "current": 3.9,
            "min": 3900.0,
            "max": 3900.0
        },
        {
            "current": 3.9,
            "min": 3900.0,
            "max": 3900.0
        },
        {
            "current": 3.9,
            "min": 3900.0,
            "max": 3900.0
        },
        {
            "current": 3.9,
            "min": 3900.0,
            "max": 3900.0
        },
        {
            "current": 3.9,
            "min": 3900.0,
            "max": 3900.0
        },
        {
            "current": 3.9,
            "min": 3900.0,
            "max": 3900.0
        },
        {
            "current": 3.9,
            "min": 3900.0,
            "max": 3900.0
        },
        {
            "current": 3.9,
            "min": 3900.0,
            "max": 3900.0
        },
        {
            "current": 3.9,
            "min": 3900.0,
            "max": 3900.0
        },
        {
            "current": 3.9,
            "min": 3900.0,
            "max": 3900.0
        },
        {
            "current": 3.9,
            "min": 3900.0,
            "max": 3900.0
        },
        {
            "current": 3.9,
            "min": 3900.0,
            "max": 3900.0
        },
        {
            "current": 3.9,
            "min": 3900.0,
            "max": 3900.0
        },
        {
            "current": 3.9,
            "min": 3900.0,
            "max": 3900.0
        },
        {
            "current": 3.5,
            "min": 3900.0,
            "max": 3900.0
        },
        {
            "current": 3.9,
            "min": 3900.0,
            "max": 3900.0
        },
        {
            "current": 3.9,
            "min": 3900.0,
            "max": 3900.0
        },
        {
            "current": 3.9,
            "min": 3900.0,
            "max": 3900.0
        },
        {
            "current": 3.9,
            "min": 3900.0,
            "max": 3900.0
        },
        {
            "current": 3.9,
            "min": 3900.0,
            "max": 3900.0
        },
        {
            "current": 3.9,
            "min": 3900.0,
            "max": 3900.0
        },
        {
            "current": 3.9,
            "min": 3900.0,
            "max": 3900.0
        },
        {
            "current": 3.5,
            "min": 3900.0,
            "max": 3900.0
        },
        {
            "current": 3.9,
            "min": 3900.0,
            "max": 3900.0
        },
        {
            "current": 3.9,
            "min": 3900.0,
            "max": 3900.0
        },
        {
            "current": 3.9,
            "min": 3900.0,
            "max": 3900.0
        },
        {
            "current": 3.9,
            "min": 3900.0,
            "max": 3900.0
        },
        {
            "current": 3.9,
            "min": 3900.0,
            "max": 3900.0
        },
        {
            "current": 3.9,
            "min": 3900.0,
            "max": 3900.0
        },
        {
            "current": 3.9,
            "min": 3900.0,
            "max": 3900.0
        },
        {
            "current": 3.9,
            "min": 3900.0,
            "max": 3900.0
        },
        {
            "current": 3.9,
            "min": 3900.0,
            "max": 3900.0
        },
        {
            "current": 3.9,
            "min": 3900.0,
            "max": 3900.0
        },
        {
            "current": 3.9,
            "min": 3900.0,
            "max": 3900.0
        },
        {
            "current": 3.9,
            "min": 3900.0,
            "max": 3900.0
        },
        {
            "current": 3.9,
            "min": 3900.0,
            "max": 3900.0
        },
        {
            "current": 3.9,
            "min": 3900.0,
            "max": 3900.0
        },
        {
            "current": 3.9,
            "min": 3900.0,
            "max": 3900.0
        }
    ],
    "disk": {
        "total": 14.915481567382812,
        "used": 8.33413314819336
    },
    "gpu": "Tesla V100-PCIE-32GB",
    "gpu_count": 1,
    "gpu_devices": [
        {
            "name": "Tesla V100-PCIE-32GB",
            "memory_total": 34359738368
        }
    ],
    "memory": {
        "total": 377.32373046875
    }
}
